{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "204a673b",
   "metadata": {},
   "source": [
    "# Session 2 Exercise: Airlines Data Cleaning\n",
    "\n",
    "**Data Science with Python - 2025 Edition**\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Exercise Objectives\n",
    "In this hands-on exercise, you will clean a real-world airlines dataset that contains:\n",
    "- Missing values in price, duration, and arrival_time\n",
    "- Outliers in price and duration\n",
    "- Typos in airline names (Sp1ceJet, Air@Asia, Vist@ra)\n",
    "- Inconsistent flight codes\n",
    "- Duplicate rows\n",
    "- Text formatting issues\n",
    "\n",
    "---\n",
    "\n",
    "## üìö What You'll Practice\n",
    "- Loading and exploring messy data\n",
    "- Identifying data quality issues\n",
    "- Applying appropriate cleaning techniques\n",
    "- Validating your cleaning results\n",
    "\n",
    "**Let's get started! üöÄ**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a8a09a",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3af1bec3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\"Libraries loaded! Ready to clean airlines data! ‚úàÔ∏è\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194d32ce",
   "metadata": {},
   "source": [
    "## üìä Load the Dirty Dataset\n",
    "\n",
    "First, let's load the messy airlines dataset that was created using the a.py script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d61a68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dirty airlines dataset\n",
    "df = pd.read_csv('airlines_flights_data_dirty.csv')\n",
    "\n",
    "print(\"Loaded airlines dataset with shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cbfe49",
   "metadata": {},
   "source": [
    "## üîç Exercise 1: Initial Data Exploration\n",
    "\n",
    "**Your Task:** Explore the dataset to understand what we're working with.\n",
    "\n",
    "**Fill in the code below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33268c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check the shape of the dataset\n",
    "print(\"Dataset shape:\", ___)\n",
    "\n",
    "# TODO: Check data types\n",
    "print(\"Data types:\")\n",
    "___\n",
    "\n",
    "# TODO: Check for missing values\n",
    "print(\"Missing values:\")\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bffcc6e",
   "metadata": {},
   "source": [
    "### ‚úÖ Solution 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0134c9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape of the dataset\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "\n",
    "# Check data types\n",
    "print(\"Data types:\")\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d0965b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643b2b70",
   "metadata": {},
   "source": [
    "## üßπ Exercise 2: Find Data Quality Issues\n",
    "\n",
    "**Your Task:** Look for specific problems in the data:\n",
    "1. Check unique airline names for typos\n",
    "2. Look for extreme values in price and duration\n",
    "3. Check for duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56687802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check unique airline names (look for typos like Sp1ceJet, Air@Asia)\n",
    "print(\"Unique airlines:\")\n",
    "___\n",
    "\n",
    "# TODO: Check price range (look for very low/high prices)\n",
    "print(\"Price statistics:\")\n",
    "___\n",
    "\n",
    "# TODO: Check duration range (look for very short/long durations)\n",
    "print(\"Duration statistics:\")\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217325f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check for duplicate rows\n",
    "print(\"Total rows:\", ___)\n",
    "print(\"Duplicate rows:\", ___)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131de10e",
   "metadata": {},
   "source": [
    "### ‚úÖ Solution 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f50f20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique airline names\n",
    "print(\"Unique airlines:\")\n",
    "df['airline'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0711c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check price range\n",
    "df['price'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76202174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check duration range\n",
    "df['duration'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95aebefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate rows\n",
    "print(\"Total rows:\", len(df))\n",
    "print(\"Duplicate rows:\", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c0dba8",
   "metadata": {},
   "source": [
    "## üìà Exercise 2.5: Visualize Outliers with Scatter Plots\n",
    "\n",
    "**Your Task:** Create simple scatter plots to spot outliers visually.\n",
    "\n",
    "Let's use plots to see the extreme values in our data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0feb8498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a scatter plot of price vs duration to spot outliers\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['duration'], df['price'])\n",
    "plt.xlabel('Duration (hours)')\n",
    "plt.ylabel('Price (‚Çπ)')\n",
    "plt.title('Price vs Duration - Can you spot the outliers?')\n",
    "___  # Add plt.show() here\n",
    "\n",
    "# TODO: Create a simple plot to see price distribution\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(df['price'], 'o', alpha=0.6)\n",
    "plt.xlabel('Flight Index')\n",
    "plt.ylabel('Price (‚Çπ)')\n",
    "plt.title('Price Distribution - Look for extreme values!')\n",
    "___  # Add plt.show() here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d178b20",
   "metadata": {},
   "source": [
    "### ‚úÖ Solution 2.5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd8a59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot of price vs duration to spot outliers\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['duration'], df['price'], alpha=0.6)\n",
    "plt.xlabel('Duration (hours)')\n",
    "plt.ylabel('Price (‚Çπ)')\n",
    "plt.title('Price vs Duration - Outliers are clearly visible!')\n",
    "plt.show()\n",
    "\n",
    "print(\"Look for:\")\n",
    "print(\"- Prices at 1 and 999999 (extreme outliers)\")\n",
    "print(\"- Durations at 0.1 and 50.0 hours (unrealistic)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89cea57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate plots for price and duration distributions\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Price distribution\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(df['price'], 'o', alpha=0.6, markersize=3)\n",
    "plt.xlabel('Flight Index')\n",
    "plt.ylabel('Price (‚Çπ)')\n",
    "plt.title('Price Distribution - Spot the extreme values!')\n",
    "\n",
    "# Duration distribution\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(df['duration'], 'o', alpha=0.6, markersize=3, color='orange')\n",
    "plt.xlabel('Flight Index')\n",
    "plt.ylabel('Duration (hours)')\n",
    "plt.title('Duration Distribution - Find the unrealistic values!')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8a1435",
   "metadata": {},
   "source": [
    "## üîß Exercise 3: Clean Missing Values\n",
    "\n",
    "**Your Task:** Handle missing values in price, duration, and arrival_time columns.\n",
    "\n",
    "**Strategy:**\n",
    "- For price: Fill with median price\n",
    "- For duration: Fill with median duration\n",
    "- For arrival_time: You can either drop these rows or fill with a placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763078aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy to work with\n",
    "df_clean = df.copy()\n",
    "\n",
    "# TODO: Fill missing prices with median price\n",
    "median_price = ___\n",
    "df_clean['price'] = ___\n",
    "\n",
    "# TODO: Fill missing duration with median duration\n",
    "median_duration = ___\n",
    "df_clean['duration'] = ___\n",
    "\n",
    "# TODO: Check if missing values are fixed\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7d8ea9",
   "metadata": {},
   "source": [
    "### ‚úÖ Solution 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3558d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy to work with\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Fill missing prices with median price\n",
    "median_price = df_clean['price'].median()\n",
    "df_clean['price'] = df_clean['price'].fillna(median_price)\n",
    "\n",
    "# Fill missing duration with median duration\n",
    "median_duration = df_clean['duration'].median()\n",
    "df_clean['duration'] = df_clean['duration'].fillna(median_duration)\n",
    "\n",
    "# For arrival_time, let's drop rows with missing values (simple approach)\n",
    "df_clean = df_clean.dropna(subset=['arrival_time'])\n",
    "\n",
    "# Check if missing values are fixed\n",
    "df_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b05077",
   "metadata": {},
   "source": [
    "## üìä Exercise 4: Fix Outliers\n",
    "\n",
    "**Your Task:** Handle extreme values in price and duration.\n",
    "\n",
    "**Strategy:**\n",
    "- Prices of 1 or 999999 are clearly wrong\n",
    "- Durations of 0.1 or 50.0 hours are unrealistic\n",
    "- Replace them with median values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024a7909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Find and fix extreme prices (1 and 999999)\n",
    "print(\"Extreme low prices:\", (df_clean['price'] == 1).sum())\n",
    "print(\"Extreme high prices:\", (df_clean['price'] == 999999).sum())\n",
    "\n",
    "# Fix extreme prices\n",
    "df_clean.loc[df_clean['price'] == 1, 'price'] = ___\n",
    "df_clean.loc[df_clean['price'] == 999999, 'price'] = ___\n",
    "\n",
    "# TODO: Find and fix extreme durations (0.1 and 50.0)\n",
    "print(\"Extreme short durations:\", (df_clean['duration'] == 0.1).sum())\n",
    "print(\"Extreme long durations:\", (df_clean['duration'] == 50.0).sum())\n",
    "\n",
    "# Fix extreme durations\n",
    "df_clean.loc[df_clean['duration'] == 0.1, 'duration'] = ___\n",
    "df_clean.loc[df_clean['duration'] == 50.0, 'duration'] = ___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d206a7a",
   "metadata": {},
   "source": [
    "### ‚úÖ Solution 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec62112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and fix extreme prices\n",
    "print(\"Extreme low prices:\", (df_clean['price'] == 1).sum())\n",
    "print(\"Extreme high prices:\", (df_clean['price'] == 999999).sum())\n",
    "\n",
    "# Fix extreme prices with median\n",
    "median_price = df_clean['price'].median()\n",
    "df_clean.loc[df_clean['price'] == 1, 'price'] = median_price\n",
    "df_clean.loc[df_clean['price'] == 999999, 'price'] = median_price\n",
    "\n",
    "# Find and fix extreme durations\n",
    "print(\"Extreme short durations:\", (df_clean['duration'] == 0.1).sum())\n",
    "print(\"Extreme long durations:\", (df_clean['duration'] == 50.0).sum())\n",
    "\n",
    "# Fix extreme durations with median\n",
    "median_duration = df_clean['duration'].median()\n",
    "df_clean.loc[df_clean['duration'] == 0.1, 'duration'] = median_duration\n",
    "df_clean.loc[df_clean['duration'] == 50.0, 'duration'] = median_duration\n",
    "\n",
    "# Check the results\n",
    "df_clean['price'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6fa5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the improvement! Compare before and after fixing outliers\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Before fixing outliers\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(df['duration'], df['price'], alpha=0.6)\n",
    "plt.xlabel('Duration (hours)')\n",
    "plt.ylabel('Price (‚Çπ)')\n",
    "plt.title('BEFORE: Price vs Duration (with outliers)')\n",
    "\n",
    "# After fixing outliers\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(df_clean['duration'], df_clean['price'], alpha=0.6, color='green')\n",
    "plt.xlabel('Duration (hours)')\n",
    "plt.ylabel('Price (‚Çπ)')\n",
    "plt.title('AFTER: Price vs Duration (outliers fixed!)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\"Much better! The data now makes sense! üéâ\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921d7af3",
   "metadata": {},
   "source": [
    "## ‚úèÔ∏è Exercise 5: Fix Airline Name Typos\n",
    "\n",
    "**Your Task:** Correct the typos in airline names.\n",
    "\n",
    "**Known Issues:**\n",
    "- \"Sp1ceJet\" should be \"SpiceJet\"\n",
    "- \"Air@Asia\" should be \"AirAsia\"\n",
    "- \"Vist@ra\" should be \"Vistara\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5521e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check current airline names\n",
    "print(\"Before fixing typos:\")\n",
    "___\n",
    "\n",
    "# TODO: Fix the typos\n",
    "df_clean['airline'] = df_clean['airline'].replace('Sp1ceJet', ___)\n",
    "df_clean['airline'] = df_clean['airline'].replace('Air@Asia', ___)\n",
    "df_clean['airline'] = df_clean['airline'].replace('Vist@ra', ___)\n",
    "\n",
    "# TODO: Check after fixing\n",
    "print(\"After fixing typos:\")\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845ee9a2",
   "metadata": {},
   "source": [
    "### ‚úÖ Solution 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172f8dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check current airline names\n",
    "print(\"Before fixing typos:\")\n",
    "df_clean['airline'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2937782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the typos\n",
    "df_clean['airline'] = df_clean['airline'].replace('Sp1ceJet', 'SpiceJet')\n",
    "df_clean['airline'] = df_clean['airline'].replace('Air@Asia', 'AirAsia')\n",
    "df_clean['airline'] = df_clean['airline'].replace('Vist@ra', 'Vistara')\n",
    "\n",
    "# Check after fixing\n",
    "print(\"After fixing typos:\")\n",
    "df_clean['airline'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac2f909",
   "metadata": {},
   "source": [
    "## üîÑ Exercise 6: Fix Flight Codes and Class Issues\n",
    "\n",
    "**Your Task:** Clean up flight codes and class names.\n",
    "\n",
    "**Issues to fix:**\n",
    "- Flight codes are in lowercase (should be uppercase)\n",
    "- Some flight codes have \"###\" prefix\n",
    "- \"Economyy\" should be \"Economy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531505af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check current flight codes\n",
    "print(\"Sample flight codes:\")\n",
    "df_clean['flight'].head(10)\n",
    "\n",
    "# TODO: Convert flight codes to uppercase\n",
    "df_clean['flight'] = ___\n",
    "\n",
    "# TODO: Remove ### prefix from flight codes\n",
    "df_clean['flight'] = df_clean['flight'].str.replace('###', '')\n",
    "\n",
    "# TODO: Check and fix class names\n",
    "print(\"Class values:\")\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55701602",
   "metadata": {},
   "source": [
    "### ‚úÖ Solution 6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2b407b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check current flight codes\n",
    "print(\"Sample flight codes:\")\n",
    "df_clean['flight'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34824f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert flight codes to uppercase\n",
    "df_clean['flight'] = df_clean['flight'].str.upper()\n",
    "\n",
    "# Remove ### prefix from flight codes\n",
    "df_clean['flight'] = df_clean['flight'].str.replace('###', '')\n",
    "\n",
    "# Check and fix class names\n",
    "print(\"Before fixing class:\")\n",
    "df_clean['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ce2401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix \"Economyy\" to \"Economy\"\n",
    "df_clean['class'] = df_clean['class'].replace('Economyy', 'Economy')\n",
    "\n",
    "print(\"After fixing class:\")\n",
    "df_clean['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268f7650",
   "metadata": {},
   "source": [
    "## üóëÔ∏è Exercise 7: Remove Duplicates\n",
    "\n",
    "**Your Task:** Remove duplicate rows from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189af543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check for duplicates\n",
    "print(\"Before removing duplicates:\")\n",
    "print(\"Total rows:\", ___)\n",
    "print(\"Duplicate rows:\", ___)\n",
    "\n",
    "# TODO: Remove duplicates\n",
    "df_clean = ___\n",
    "\n",
    "# TODO: Check after removing duplicates\n",
    "print(\"After removing duplicates:\")\n",
    "print(\"Total rows:\", ___)\n",
    "print(\"Duplicate rows:\", ___)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d2bf0c",
   "metadata": {},
   "source": [
    "### ‚úÖ Solution 7:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04562213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "print(\"Before removing duplicates:\")\n",
    "print(\"Total rows:\", len(df_clean))\n",
    "print(\"Duplicate rows:\", df_clean.duplicated().sum())\n",
    "\n",
    "# Remove duplicates\n",
    "df_clean = df_clean.drop_duplicates()\n",
    "\n",
    "# Check after removing duplicates\n",
    "print(\"After removing duplicates:\")\n",
    "print(\"Total rows:\", len(df_clean))\n",
    "print(\"Duplicate rows:\", df_clean.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c69349d",
   "metadata": {},
   "source": [
    "## üìä Exercise 8: Final Validation\n",
    "\n",
    "**Your Task:** Validate that all cleaning was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c172f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check final data quality\n",
    "print(\"FINAL DATASET QUALITY CHECK:\")\n",
    "print(\"Shape:\", ___)\n",
    "print(\"Missing values:\", ___)\n",
    "print(\"Duplicate rows:\", ___)\n",
    "\n",
    "# TODO: Check price range\n",
    "print(\"\\nPrice range:\", df_clean['price'].min(), \"to\", df_clean['price'].max())\n",
    "\n",
    "# TODO: Check duration range  \n",
    "print(\"Duration range:\", df_clean['duration'].min(), \"to\", df_clean['duration'].max())\n",
    "\n",
    "# TODO: Check airline names\n",
    "print(\"\\nAirline names:\")\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c360ae1",
   "metadata": {},
   "source": [
    "### ‚úÖ Solution 8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9f7b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check final data quality\n",
    "print(\"FINAL DATASET QUALITY CHECK:\")\n",
    "print(\"Shape:\", df_clean.shape)\n",
    "print(\"Missing values:\", df_clean.isnull().sum().sum())\n",
    "print(\"Duplicate rows:\", df_clean.duplicated().sum())\n",
    "\n",
    "# Check price range\n",
    "print(\"\\nPrice range:\", df_clean['price'].min(), \"to\", df_clean['price'].max())\n",
    "\n",
    "# Check duration range  \n",
    "print(\"Duration range:\", df_clean['duration'].min(), \"to\", df_clean['duration'].max())\n",
    "\n",
    "# Check airline names\n",
    "print(\"\\nAirline names:\")\n",
    "df_clean['airline'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec30b5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample of clean data\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec17c874",
   "metadata": {},
   "source": [
    "## üíæ Save Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7aa2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned dataset\n",
    "df_clean.to_csv('airlines_flights_data_clean.csv', index=False)\n",
    "\n",
    "\"‚úÖ Clean airlines dataset saved! Ready for analysis! ‚úàÔ∏è\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e37e7b6",
   "metadata": {},
   "source": [
    "## üéì What You Accomplished!\n",
    "\n",
    "### ‚úÖ Data Cleaning Tasks Completed:\n",
    "1. **‚úÖ Handled Missing Values** - Filled price and duration with medians\n",
    "2. **‚úÖ Fixed Outliers** - Replaced extreme prices (1, 999999) and durations (0.1, 50.0)\n",
    "3. **‚úÖ Corrected Typos** - Fixed airline names (Sp1ceJet ‚Üí SpiceJet, etc.)\n",
    "4. **‚úÖ Standardized Text** - Made flight codes uppercase, removed ### prefix\n",
    "5. **‚úÖ Fixed Categories** - Corrected \"Economyy\" to \"Economy\"\n",
    "6. **‚úÖ Removed Duplicates** - Cleaned duplicate rows\n",
    "7. **‚úÖ Validated Results** - Confirmed all issues were resolved\n",
    "\n",
    "### üìä Before vs After:\n",
    "- **Missing Values**: Fixed all missing data\n",
    "- **Outliers**: Replaced unrealistic values with medians\n",
    "- **Text Issues**: Standardized airline names and flight codes\n",
    "- **Duplicates**: Removed duplicate entries\n",
    "- **Data Quality**: Dataset is now ready for analysis!\n",
    "\n",
    "### üöÄ What's Next:\n",
    "- Use this clean dataset for visualization\n",
    "- Perform exploratory data analysis\n",
    "- Build predictive models\n",
    "- Create insights about flight patterns\n",
    "\n",
    "**Congratulations! You've successfully cleaned a real-world dataset! üéâ**\n",
    "\n",
    "---\n",
    "\n",
    "*This exercise demonstrates the importance of data cleaning in real projects. Clean data leads to reliable insights and better machine learning models!*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
