{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d73ad83e",
   "metadata": {},
   "source": [
    "# Session 2: Data Cleaning and Preprocessing\n",
    "\n",
    "**Data Science with Python - 2025 Edition**\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "By the end of this session, you will be able to:\n",
    "- Remove uncertainty values and handle missing data\n",
    "- Detect and handle outliers effectively\n",
    "- Fix inconsistent data formats and standardize entries\n",
    "- Remove duplicates and correct data entry errors\n",
    "- Handle categorical inconsistencies\n",
    "- Resolve data type mismatches\n",
    "- Standardize units and scales\n",
    "- Filter irrelevant or noisy data\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Why Data Cleaning Matters\n",
    "\n",
    "**\"Garbage in, garbage out\"** - This famous saying perfectly captures why data cleaning is crucial in data science.\n",
    "\n",
    "- Real-world data is **messy** and **incomplete**\n",
    "- Poor data quality leads to **incorrect insights**\n",
    "- Data cleaning can take **60-80%** of a data scientist's time\n",
    "- Clean data = **Better models** and **Reliable results**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0118f535",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffe29a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\"Libraries imported successfully! We are ready to clean our data!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69684b4",
   "metadata": {},
   "source": [
    "## üìä Create Sample Messy Dataset\n",
    "\n",
    "Let's create a realistic messy dataset that contains all the common data quality issues we'll address:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "265b4975",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      2\u001b[39m data = {\n\u001b[32m      3\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m: [\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m, \u001b[32m6\u001b[39m, \u001b[32m7\u001b[39m, \u001b[32m8\u001b[39m, \u001b[32m1\u001b[39m],  \u001b[38;5;66;03m# Duplicate ID at the end\u001b[39;00m\n\u001b[32m      4\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m: [\u001b[33m'\u001b[39m\u001b[33mJohn\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mjane\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mALICE\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mBob\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m?\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mDiana\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mEve\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mFrank\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mJohn\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mdepartment\u001b[39m\u001b[33m'\u001b[39m: [\u001b[33m'\u001b[39m\u001b[33mIT\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mhr\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mFinance\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mIT\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mMarketing\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mHR\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mfinance\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mit\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mIT\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      9\u001b[39m }\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Create DataFrame\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m df = \u001b[43mpd\u001b[49m.DataFrame(data)\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCreated messy dataset with these problems:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m- Question marks (?) for missing values\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a simple messy dataset\n",
    "data = {\n",
    "    'id': [1, 2, 3, 4, 5, 6, 7, 8, 1],  # Duplicate ID at the end\n",
    "    'name': ['John', 'jane', 'ALICE', 'Bob', '?', 'Diana', 'Eve', 'Frank', 'John'],\n",
    "    'age': [25, 30, '?', 35, -999, 28, 45, 150, 25],\n",
    "    'gender': ['Male', 'female', 'F', 'M', '?', 'Female', 'M', 'F', 'Male'],\n",
    "    'salary': [50000, 60000, 75000, None, 80000, 55000, 9999999, 45000, 50000],\n",
    "    'department': ['IT', 'hr', 'Finance', 'IT', 'Marketing', 'HR', 'finance', 'it', 'IT']\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Created messy dataset with these problems:\")\n",
    "print(\"- Question marks (?) for missing values\")\n",
    "print(\"- -999 as placeholder for missing age\") \n",
    "print(\"- Different case letters (john, ALICE)\")\n",
    "print(\"- Very high salary (9999999)\")\n",
    "print(\"- Very high age (150)\")\n",
    "print(\"- Duplicate rows\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba075440",
   "metadata": {},
   "source": [
    "## üîç Initial Data Exploration\n",
    "\n",
    "Before cleaning, let's understand what we're working with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384d0025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at our data\n",
    "print(\"Dataset shape (rows, columns):\", df.shape)\n",
    "print(\"Data types:\")\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1674bb96",
   "metadata": {},
   "source": [
    "## üßπ Step 1: Uncertainty Removal\n",
    "\n",
    "First, let's identify and handle uncertainty values like '?', 'unknown', and placeholder values like '-999':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c7c7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for uncertainty values like '?' and -999\n",
    "print(\"Names with '?':\", (df['name'] == '?').sum())\n",
    "print(\"Ages with '?':\", (df['age'] == '?').sum()) \n",
    "print(\"Genders with '?':\", (df['gender'] == '?').sum())\n",
    "print(\"Ages with -999:\", (df['age'] == -999).sum())\n",
    "\n",
    "# Show rows with problems\n",
    "df[df['age'] == -999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2894713c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of our data to clean\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Replace '?' with missing values (NaN)\n",
    "df_clean = df_clean.replace('?', np.nan)\n",
    "\n",
    "# Replace -999 with missing values\n",
    "df_clean = df_clean.replace(-999, np.nan)\n",
    "\n",
    "print(\"After removing uncertainty values:\")\n",
    "df_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274e1208",
   "metadata": {},
   "source": [
    "## üï≥Ô∏è Step 2: Treating Missing Values\n",
    "\n",
    "Now let's handle the missing values using appropriate strategies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb18fc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count missing values\n",
    "df_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e94bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing names with 'Unknown'\n",
    "df_clean['name'] = df_clean['name'].fillna('Unknown')\n",
    "\n",
    "# Convert age to numbers first\n",
    "df_clean['age'] = pd.to_numeric(df_clean['age'], errors='coerce')\n",
    "\n",
    "# Fill missing ages with the average age\n",
    "average_age = df_clean['age'].mean()\n",
    "df_clean['age'] = df_clean['age'].fillna(average_age)\n",
    "\n",
    "# Fill missing salaries with the average salary\n",
    "average_salary = df_clean['salary'].mean()\n",
    "df_clean['salary'] = df_clean['salary'].fillna(average_salary)\n",
    "\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3426c0",
   "metadata": {},
   "source": [
    "## üìä Step 3: Handling Outliers\n",
    "\n",
    "Let's identify and handle outliers in numerical columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef206c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for unrealistic ages\n",
    "df_clean['age'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44f8007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix unrealistic ages (over 100 becomes average age)\n",
    "average_age = df_clean['age'].mean()\n",
    "df_clean.loc[df_clean['age'] > 100, 'age'] = average_age\n",
    "\n",
    "# Fix unrealistic salaries (over 500,000 becomes average salary)\n",
    "average_salary = df_clean['salary'].mean()\n",
    "df_clean.loc[df_clean['salary'] > 500000, 'salary'] = average_salary\n",
    "\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ffd52f",
   "metadata": {},
   "source": [
    "## üìÖ Step 4: Fixing Text Cases\n",
    "\n",
    "Let's make sure names and departments have consistent formatting:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35dc612",
   "metadata": {},
   "source": [
    "## üîÑ Step 5: Removing Duplicate Entries\n",
    "\n",
    "Let's identify and handle duplicate records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5de4e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "print(\"Total rows:\", len(df_clean))\n",
    "print(\"Duplicate rows:\", df_clean.duplicated().sum())\n",
    "print(\"Duplicate IDs:\", df_clean['id'].duplicated().sum())\n",
    "\n",
    "# Show duplicate rows\n",
    "df_clean[df_clean.duplicated(keep=False)].sort_values('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1dae67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rows (keep the first one)\n",
    "before_count = len(df_clean)\n",
    "df_clean = df_clean.drop_duplicates()\n",
    "after_count = len(df_clean)\n",
    "\n",
    "print(\"Removed\", before_count - after_count, \"duplicate rows\")\n",
    "\n",
    "# Make names look nice (Title Case)\n",
    "df_clean['name'] = df_clean['name'].str.title()\n",
    "\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1f2594",
   "metadata": {},
   "source": [
    "## ‚úèÔ∏è Step 6: Correcting Data Entry Errors\n",
    "\n",
    "Let's identify and fix common data entry errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15111a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for reasonable age range (18 to 80)\n",
    "weird_ages = df_clean[(df_clean['age'] < 18) | (df_clean['age'] > 80)]\n",
    "print(\"Ages outside normal range (18-80):\", len(weird_ages))\n",
    "\n",
    "# Check for reasonable salary range  \n",
    "weird_salaries = df_clean[(df_clean['salary'] < 20000) | (df_clean['salary'] > 200000)]\n",
    "print(\"Salaries outside normal range (20,000 - 200,000):\", len(weird_salaries))\n",
    "\n",
    "weird_salaries if len(weird_salaries) > 0 else \"All salaries look good!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b436ffb",
   "metadata": {},
   "source": [
    "## üè∑Ô∏è Step 7: Dealing with Categorical Inconsistencies\n",
    "\n",
    "Let's standardize categorical variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1f5add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at gender values\n",
    "df_clean['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f418132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make gender values consistent\n",
    "df_clean['gender'] = df_clean['gender'].replace('F', 'Female')\n",
    "df_clean['gender'] = df_clean['gender'].replace('M', 'Male')\n",
    "df_clean['gender'] = df_clean['gender'].replace('female', 'Female')\n",
    "\n",
    "# Make department names consistent (proper case)\n",
    "df_clean['department'] = df_clean['department'].replace('hr', 'HR')\n",
    "df_clean['department'] = df_clean['department'].replace('it', 'IT')\n",
    "df_clean['department'] = df_clean['department'].replace('finance', 'Finance')\n",
    "\n",
    "df_clean['department'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e56f01e",
   "metadata": {},
   "source": [
    "## üî¢ Step 8: Resolving Data Type Mismatches\n",
    "\n",
    "Let's ensure all columns have the correct data types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f60b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert age to whole numbers\n",
    "df_clean['age'] = df_clean['age'].round().astype(int)\n",
    "\n",
    "# Convert salary to whole numbers  \n",
    "df_clean['salary'] = df_clean['salary'].round().astype(int)\n",
    "\n",
    "df_clean.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4b66aa",
   "metadata": {},
   "source": [
    "## üîç Step 9: Final Check\n",
    "\n",
    "Let's make sure our data looks good:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2c1660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final check of our clean data\n",
    "print(\"Shape:\", df_clean.shape)\n",
    "print(\"Missing values:\", df_clean.isnull().sum().sum())\n",
    "print(\"Age range:\", df_clean['age'].min(), \"to\", df_clean['age'].max())\n",
    "print(\"Salary range: $\", df_clean['salary'].min(), \"to $\", df_clean['salary'].max())\n",
    "\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90468a0",
   "metadata": {},
   "source": [
    "## üìä Before vs After Comparison\n",
    "\n",
    "Let's see how much we improved our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d803b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare original vs cleaned data\n",
    "print(\"BEFORE CLEANING:\")\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Missing values:\", df.isnull().sum().sum())\n",
    "print(\"Data types:\", list(df.dtypes))\n",
    "print()\n",
    "\n",
    "print(\"AFTER CLEANING:\")\n",
    "print(\"Shape:\", df_clean.shape)  \n",
    "print(\"Missing values:\", df_clean.isnull().sum().sum())\n",
    "print(\"Data types:\", list(df_clean.dtypes))\n",
    "print()\n",
    "\n",
    "print(\"IMPROVEMENTS MADE:\")\n",
    "print(\"‚úì Removed uncertainty values (?, -999)\")\n",
    "print(\"‚úì Filled missing values with averages\")\n",
    "print(\"‚úì Fixed unrealistic ages and salaries\") \n",
    "print(\"‚úì Removed duplicate rows\")\n",
    "print(\"‚úì Standardized text formats\")\n",
    "print(\"‚úì Made gender and department names consistent\")\n",
    "print(\"‚úì Converted to proper data types\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb316ef",
   "metadata": {},
   "source": [
    "## üíæ Save Cleaned Dataset\n",
    "\n",
    "Let's save our cleaned dataset for future use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ece3874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save our clean data\n",
    "df_clean.to_csv('clean_employee_data.csv', index=False)\n",
    "\n",
    "\"‚úÖ Saved clean data to 'clean_employee_data.csv' - Ready for analysis!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609ef945",
   "metadata": {},
   "source": [
    "## üéì What We Learned\n",
    "\n",
    "### Data Cleaning Steps We Did:\n",
    "1. ‚úÖ **Found Problem Values**: Looked for '?', -999, and missing data\n",
    "2. ‚úÖ **Fixed Missing Values**: Replaced with averages or 'Unknown'\n",
    "3. ‚úÖ **Fixed Unrealistic Values**: Changed very high ages and salaries\n",
    "4. ‚úÖ **Removed Duplicates**: Kept only unique rows\n",
    "5. ‚úÖ **Fixed Text Formatting**: Made names and departments consistent\n",
    "6. ‚úÖ **Standardized Categories**: Made M/F into Male/Female\n",
    "7. ‚úÖ **Fixed Data Types**: Made sure numbers are numbers\n",
    "\n",
    "### Why Data Cleaning is Important:\n",
    "- **Real data is messy** - it has errors and missing pieces\n",
    "- **Clean data = better results** - your analysis will be more accurate\n",
    "- **It takes time** - but it's worth it!\n",
    "\n",
    "### Remember:\n",
    "- Always look at your data first\n",
    "- Make a copy before cleaning\n",
    "- Check your work at each step\n",
    "- Document what you did\n",
    "\n",
    "### What's Next:\n",
    "- Now we can analyze our clean data\n",
    "- Make charts and graphs\n",
    "- Find patterns and insights\n",
    "- Build models\n",
    "\n",
    "**Great job! You've learned the basics of data cleaning! \udf89**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
